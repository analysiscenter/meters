{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with _Water meters_!\n",
    "In this notebook we will train ResNet101, DenseNet121 and VGG19 to predict numbers on water meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.6.1 :: Anaconda custom (64-bit)\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 01 14:29:10 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.94                 Driver Version: 384.94                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1050   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   41C    P8    N/A /  N/A |     77MiB /  4096MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID  Type  Process name                               Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm import tqdm as tqn\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('..//..')\n",
    "\n",
    "import meters as ms\n",
    "from meters.batch import MeterBatch\n",
    "# from meter_batch import MeterBatch\n",
    "\n",
    "from meters.dataset import B,V,F,R,P, FilesIndex, Dataset, Pipeline\n",
    "from meters.dataset.dataset.models.tf import ResNet18, DenseNet121, VGG19\n",
    "from detection_model import NearestDetection, ClassificationModel\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fileindex witch allows us to loading only part of images instead all images.\n",
    "\n",
    "`src` - the path to images in blosc format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp = (\n",
    "#     Pipeline()\n",
    "#     .load(src=src, fmt='blosc', components='images')\n",
    "#     .load(src='labels/data.csv',\\\n",
    "#           fmt='csv',\\\n",
    "#           components=['coordinates', 'labels'],\\\n",
    "#           index_col='file_name') << dset.train)\n",
    "# btch = tmp.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = 'saved_images_small/'\n",
    "\n",
    "fileindex = FilesIndex(path=src+'*.blosc', no_ext=True)\n",
    "\n",
    "dset = Dataset(fileindex, batch_class=MeterBatch)\n",
    "# dset.cv_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write pipeline to load and crop data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25\n",
    "NUM_DIGITS = 8\n",
    "HEIGHT = 32\n",
    "WIDTH = 16\n",
    "VERTICALE_SCALE = 2.5\n",
    "HORIZONTAL_SCALE = 2\n",
    "NEW_SIZE = (int(VERTICALE_SCALE * HEIGHT), int(np.round(WIDTH * NUM_DIGITS * HORIZONTAL_SCALE)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factor_sampler(size, p_square = 0.5):\n",
    "    if np.random.binomial(1, p_square):\n",
    "        return np.random.uniform(0.3, 1.7, (size,))\n",
    "    return np.random.uniform(0.3, 1.7, (size,2))\n",
    "\n",
    "def shift_sampler(size):\n",
    "    return np.hstack((np.random.uniform(-60, 60, (size, 1)),\\\n",
    "                      np.random.uniform(-15, 10, (size, 1)),\\\n",
    "                      np.zeros((size, 1))))\n",
    "\n",
    "def shape_sampler(size, crop_size=1):\n",
    "    return np.random.randint(20, 50, (size, crop_size, 2))\n",
    "\n",
    "def color_sampler(size, crop_size=1):\n",
    "    return np.random.uniform(0, 1, (size, crop_size, 3))\n",
    "\n",
    "def background_sampler(size, shape=(120, 120, 3), p_solid = 0.5):\n",
    "    if np.random.binomial(1, p_solid):\n",
    "        return np.ones((size, 120,120, 3))*color_sampler(size)[:, np.newaxis,...]\n",
    "    return np.random.uniform(0, 1, (size,) + shape)\n",
    "\n",
    "def random_origin_sampler(size, max_=3):\n",
    "    return [['random'] * np.random.randint(0, max_) for _ in range(size)]\n",
    "channels = np.array((0, 1, 2, (0, 1), (0, 2), (1, 2), (0, 1, 2)), dtype=object)\n",
    "def channels_sampler(size):\n",
    "    return channels[np.random.randint(len(channels), size=size)]\n",
    "\n",
    "mode_generator=lambda size: np.random.choice(['constant', 'nearest', 'wrap'], size)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_ppl = (\n",
    "    Pipeline()\n",
    "    .load(src='saved_images_small/', fmt='blosc', components='images')\n",
    "    .load(src='saved_labels_small.csv', fmt='csv', index_col='file_name', components='labels')\n",
    "    .load(src='saved_background_small/', fmt='blosc', components='background')\n",
    "    .one_hot()\n",
    "    .generate_data(n_digits=NUM_DIGITS, normalize=True, n_workers=1)\n",
    "    .multiply(multiplier=1., preserve_type=False, \n",
    "              src='new_images',\\\n",
    "              dst='new_images')\n",
    "#     .put_on_background(origin='random', background=P(R(background_sampler)), mask=0.03,\n",
    "# #                        src=['new_images'],\\\n",
    "# #                        dst=['new_images'])\n",
    "#                       )\n",
    "# #                        .salt(size=lambda: np.random.randint(1, 10, 2),\\\n",
    "# #           color=lambda: np.random.uniform(0, 1, 3),\\\n",
    "# #           p_noise=P(R('uniform', 0.005, 0.01)), p=0.1, \n",
    "# #           src=['new_images'],\\\n",
    "# #           dst=['new_images'])\n",
    "#     .posterize(colors_number=R('randint',8,254), p=0.5,\n",
    "# # #                  src=['new_images'],\\\n",
    "# # #                  dst=['new_images']\n",
    "#               )\n",
    "#     .invert(channels=P(R(channels_sampler)), p=0.3)\n",
    "#     .multiplicative_noise(noise=lambda size: np.random.uniform(0.9, 1.1,size=size), p=0.9)\\\n",
    "#     .additive_noise(noise=lambda size: np.random.normal(0, 0.01,size=size), p=0.9)\\\n",
    "#     .gaussian_filter(sigma=P(R('uniform', 0.001, 1)), p=1)\n",
    "    << dset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images']\n",
      "10\n",
      "1\n",
      "1\n",
      "assembling\n",
      "comp images\n",
      "10\n",
      "1\n",
      "assembling component images\n",
      "succes (10, 32, 16, 3)\n",
      "['background']\n",
      "10\n",
      "1\n",
      "1\n",
      "assembling\n",
      "comp background\n",
      "10\n",
      "1\n",
      "assembling component background\n",
      "succes (10, 80, 192, 3)\n",
      "labels\n",
      "10\n",
      "__________________one component\n",
      "1\n",
      "1\n",
      "assembling\n",
      "comp labels\n",
      "10\n",
      "assembling component labels\n",
      "succes (100,)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "inside generate_data: canvas.shape is (80, 192, 3)\n",
      "('new_images', 'labels', 'coordinates', 'confidence')\n",
      "10\n",
      "10\n",
      "4\n",
      "assembling\n",
      "comp new_images\n",
      "10\n",
      "80\n",
      "assembling component new_images\n",
      "succes (800, 192, 3)\n",
      "(800, 192, 3)\n",
      "assembling\n",
      "comp labels\n",
      "10\n",
      "assembling component labels\n",
      "succes (80,)\n",
      "assembling\n",
      "comp coordinates\n",
      "10\n",
      "assembling component coordinates\n",
      "succes (80, 4)\n",
      "assembling\n",
      "comp confidence\n",
      "10\n",
      "assembling component confidence\n",
      "succes (80, 1)\n",
      "inside multiply result.shape is inside multiply result.shape is inside multiply result.shape is inside multiply result.shape is inside multiply result.shape is inside multiply result.shape is inside multiply result.shape is inside multiply result.shape is inside multiply result.shape is inside multiply result.shape is         (192, 3)  (192, 3)(192, 3)(192, 3)(192, 3)(192, 3)(192, 3)(192, 3)(192, 3)\n",
      "\n",
      "(192, 3)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dst isdst is\n",
      "\n",
      "\n",
      "dst isdst is  dst isdst isdst isdst isdst is dst isnew_images    new_images   new_imagesnew_imagesnew_imagesnew_images\n",
      "new_images\n",
      "new_imagesnew_images\n",
      "new_images\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "new_images\n",
      "10\n",
      "__________________one component\n",
      "1\n",
      "1\n",
      "assembling\n",
      "comp new_images\n",
      "10\n",
      "192\n",
      "assembling component new_images\n",
      "succes (1920, 3)\n",
      "(1920, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "NUM_ITERS = 1\n",
    "for i in tqn(range(NUM_ITERS)):\n",
    "    tr = load_ppl.next_batch(BATCH_SIZE, n_epochs=None, suffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = [np.ones((2,3,4,5))]*10\n",
    "print(len(a))\n",
    "print(len(list(zip(*a))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With config create model parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-28b475b7a8bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3155\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3156\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3157\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   3158\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3159\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1895\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1896\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1898\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5122\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5124\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5125\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    598\u001b[0m         if (self._A.ndim not in (2, 3) or\n\u001b[0;32m    599\u001b[0m                 (self._A.ndim == 3 and self._A.shape[-1] not in (3, 4))):\n\u001b[1;32m--> 600\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAIQCAYAAABXMb6PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x272bb11ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print((tr.data.new_images.shape))\n",
    "    plt.imshow(tr.data.new_images[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(tr.data.images[-10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr.data.confidence[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputs_config = {\n",
    "#     'images': {'shape': NEW_SIZE},\n",
    "#     'labels': {'classes': (10), 'transform': 'ohe', 'name': 'targets'}\n",
    "# }\n",
    "\n",
    "# config = {\n",
    "#     'inputs': inputs_config,\n",
    "#     'optimizer': 'Adam',\n",
    "#     'loss': 'ce',\n",
    "#     'input_block/inputs': 'images',\n",
    "#     'head/units': [10],\n",
    "#     'output': dict(ops=['labels', 'proba', 'accuracy'])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_l1(labels, predictions, mu=0.02, scope=None, num_digits = 8, *args, **kwargs):\n",
    "    losses = 0\n",
    "    for digit in range(num_digits):\n",
    "        error = predictions[:, digit, :] - labels[:, digit, :]\n",
    "        abs_error = tf.abs(error)\n",
    "        quadratic = tf.minimum(mu, abs_error)\n",
    "        losses += quadratic ** 2 / (2 * mu) + abs_error - quadratic\n",
    "    return tf.reduce_mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placeholders_config = {'images': {'shape': NEW_SIZE,\n",
    "                                  'name': 'reshaped_images'},\n",
    "                       'labels': {'shape': (NUM_DIGITS * 10)},\n",
    "                       'coordinates': {'shape': (NUM_DIGITS, 4), 'name': 'targets'},\n",
    "                       'confidence': {'shape': (NUM_DIGITS, 1)}\n",
    "                      }\n",
    "                       \n",
    "config={'inputs': placeholders_config,\n",
    "        'input_block/inputs': 'images',\n",
    "        'loss': smooth_l1,\n",
    "        'num_digits': NUM_DIGITS,\n",
    "        'output': dict(ops=['labels', 'proba', 'accuracy'])\n",
    "}\n",
    "\n",
    "\n",
    "saved_fetches=[V('loss'),\n",
    "               B('predicted_bb'),\n",
    "               V('mse'),\n",
    "               V('ce_loss')]\n",
    "\n",
    "fetches_list=['loss',\n",
    "              'NearestDetection/all_predictions',\n",
    "              'NearestDetection/mse',\n",
    "              'NearestDetection/ce_loss']\n",
    "\n",
    "saved_feed_dict={'images': B('images'),\n",
    "                 'labels': B('labels'),\n",
    "                 'coordinates': B('coordinates'),\n",
    "                 'confidence': B('confidence')\n",
    "                }\n",
    "#         'optimizer':  {'name': 'Momentum', 'momentum': 0.5, 'learning_rate': 0.1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_src= '../data/images/'\n",
    "\n",
    "fileindex = FilesIndex(path=t_src+'*.blosc', no_ext=True)\n",
    "\n",
    "dset = Dataset(fileindex, batch_class=MeterBatch)\n",
    "\n",
    "\n",
    "save_digits_ppl = (\n",
    "    Pipeline()\n",
    "    .load(src=t_src, fmt='blosc', components='images')\n",
    "    .load(src='../data/labels/data.csv',\\\n",
    "          fmt='csv',\\\n",
    "          components=['coordinates', 'labels'],\\\n",
    "          index_col='file_name')\n",
    "    .crop_from_bbox()\n",
    "    .crop_background(new_size=NEW_SIZE)\n",
    "    .dump(dst='./saved_background/', fmt='blosc', mode='w', components='background') << dset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 497\n",
    "NUM_ITERS = 1\n",
    "for i in tqn(range(NUM_ITERS)):\n",
    "    tr = save_digits_ppl.next_batch(BATCH_SIZE, n_epochs=None, suffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will experements with models. For this create dict with:\n",
    "* `key` - model\n",
    "* `value` - model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [NearestDetection]\n",
    "models_names = ['NearestDetection']\n",
    "models_dict = dict(zip(models_names, models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import dill\n",
    "# import blosc\n",
    "# for i in range(40):\n",
    "#     with open('saved_background/' + str(i) + '.blosc', 'rb') as f:\n",
    "#         data = dill.loads(blosc.decompress(f.read()))\n",
    "#         plt.imshow(data['background'])\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ppl(model, name):\n",
    "    \"\"\"\"Create train and test pipeline using given `model` and `name`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Dataset model\n",
    "        preloaded model from dataset\n",
    "    \n",
    "    name : str\n",
    "        name of model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train_ppl : Dataset pipeline\n",
    "        train pipeline\n",
    "\n",
    "    test_ppl : Dataset pipeline\n",
    "        test pipeline\"\"\"\n",
    "    train_ppl = (\n",
    "        (load_ppl << dset.train)\n",
    "        .init_variable('model', model)\n",
    "        .init_variable('loss', init_on_each_run=list)\n",
    "        .init_variable('mse', init_on_each_run=list)\n",
    "        .init_variable('ce_loss', init_on_each_run=list)\n",
    "        .init_model('dynamic',\n",
    "                    V('model'),\n",
    "                    name,\n",
    "                    config=config)\n",
    "        .train_model(name,\n",
    "                     fetches=fetches_list,\n",
    "                     feed_dict=saved_feed_dict,\n",
    "                     save_to=saved_fetches, \n",
    "                     mode='a')\n",
    "    )\n",
    "\n",
    "    test_ppl = (\n",
    "        (load_ppl << dset.test)\n",
    "        .init_variable('loss', init_on_each_run=list)\n",
    "        .init_variable('mse', init_on_each_run=list)\n",
    "        .init_variable('ce_loss', init_on_each_run=list)\n",
    "        .init_variable('proba', init_on_each_run=list)\n",
    "        .init_variable('target', init_on_each_run=list)\n",
    "        .init_variable('accuracy', init_on_each_run=list)\n",
    "        .import_model(name, train_ppl)\n",
    "        .predict_model(name,\n",
    "                       fetches=fetches_list,\n",
    "                       feed_dict=saved_feed_dict,\n",
    "                       save_to=saved_fetches, \n",
    "                       mode='a')\n",
    "    )\n",
    "    pred_ppl = (\n",
    "    (load_ppl << dset.test)\n",
    "    .init_variable('loss', init_on_each_run=list)\n",
    "    .import_model(name, train_ppl)\n",
    "    .predict_model(name,\n",
    "                   fetches=fetches_list,\n",
    "                   feed_dict=saved_feed_dict,\n",
    "                   save_to=saved_fetches, \n",
    "                   mode='a')\n",
    "    )\n",
    "    return train_ppl, test_ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train pipelines with different models and save it after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_ITERS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in black_list:\n",
    "    os.remove(\"saved_images/\" + str(filename) + \".blosc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global_acc = []\n",
    "for name, model in models_dict.items():\n",
    "    print(name)\n",
    "    train_ppl, test_ppl = get_ppl(model, name)\n",
    "#     for i in tqn(range(NUM_ITERS)):\n",
    "#         tr = train_ppl.next_batch(BATCH_SIZE, n_epochs=None, suffle=True, drop_last=True)\n",
    "#         te = test_ppl.next_batch(BATCH_SIZE, n_epochs=None, suffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_ITERS = 5000\n",
    "BATCH_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in tqn(range(NUM_ITERS)):\n",
    "    tr = train_ppl.next_batch(BATCH_SIZE, n_epochs=None, suffle=True, drop_last=True)\n",
    "    te = test_ppl.next_batch(BATCH_SIZE, n_epochs=None, suffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_ITERS = 4000\n",
    "for i in tqn(range(NUM_ITERS)):\n",
    "    tr = train_ppl.next_batch(BATCH_SIZE, n_epochs=None, suffle=True, drop_last=True)\n",
    "#     te = test_ppl.next_batch(BATCH_SIZE, n_epochs=None, suffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ppl.save_model(name, path='Sailor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean((np.array(test_ppl.get_variable('loss')) - np.array(test_ppl.get_variable('ce_loss')))[-500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot((np.array(test_ppl.get_variable('loss')) - np.array(test_ppl.get_variable('ce_loss')))[-500:], label='ResNet' + 'loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(test_ppl.get_variable('mse')[-500:], label='ResNet' + 'loss')\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_ppl.get_variable('loss'), label='ResNet' + 'loss')\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_ppl.get_variable('ce_loss'), label='ResNet' + 'loss')\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_ppl.get_variable('mse')[-500:], label='ResNet' + 'loss')\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(np.array((test_ppl.get_variable('mse')[-20:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(np.array((train_ppl.get_variable('loss')[-20:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(np.array((train_ppl.get_variable('mse')[-100:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ppl.save_model(name, path='NearestDetection-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_placeholders_config = {'images': {'shape': NEW_SIZE,\n",
    "#                                   'name': 'reshaped_images'},\n",
    "#                        'labels': {\n",
    "#                                   'shape': (10),\n",
    "#                                   'name': 'targets'},\n",
    "# #                        'coordinates': {'shape': (NUM_DIGITS, 4)},\n",
    "#                       }\n",
    "                       \n",
    "# classification_config={'inputs': class_placeholders_config,\n",
    "#         'input_block/inputs': 'images',\n",
    "# #         'loss': None,\n",
    "#         'num_digits': NUM_DIGITS,\n",
    "#         'output': dict(ops=['labels', 'proba', 'accuracy'])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config['load'] = {'path':'./NearestDetection/'}\n",
    "# config['load']['checkpoint'] = None\n",
    "# config['build'] = False\n",
    "model = NearestDetection(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_placeholders_config = {'images': {'shape': (HEIGHT, WIDTH, 3), 'name': 'reshaped_images'},\n",
    "                             'labels': {'shape': (10), 'name': 'targets'},\n",
    "#                        'coordinates': {'shape': (NUM_DIGITS, 4)},\n",
    "                      }\n",
    "                       \n",
    "classification_config={'inputs': class_placeholders_config,\n",
    "        'input_block/inputs': 'images',\n",
    "        'loss': 'ce',\n",
    "        'num_digits': NUM_DIGITS,\n",
    "        'output': dict(ops=['labels', 'proba', 'accuracy'])\n",
    "}\n",
    "classification_config['load'] = {'path':'./ClassificationModel/'}\n",
    "classification_config['load']['graph'] = None\n",
    "\n",
    "classification_config['build'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_model = ClassificationModel(session=None, config=classification_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from meters.dataset.dataset.models.tf import TFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ppl = (\n",
    "    (load_ppl << dset.test)\n",
    "    .init_variable('loss', init_on_each_run=list)\n",
    "    .init_variable('mse', init_on_each_run=list)\n",
    "    .init_variable('accuracy', init_on_each_run=list)\n",
    "    .init_variable('ce_loss', init_on_each_run=list)\n",
    "#     .import_model('NearestDetection', train_ppl)\n",
    "    .init_model('dynamic', TFModel, 'NearestDetection', config={'load': {'path': './Sailor/'}, 'build': False})\n",
    "    .predict_model('NearestDetection',\n",
    "                   fetches=fetches_list,\n",
    "                   feed_dict=saved_feed_dict,\n",
    "                   save_to=saved_fetches, \n",
    "                   mode='w')\n",
    "    .crop_predictions(n_workers=1)\n",
    "    .split_cropped()\n",
    "    .compute_confidence_accuracy()\n",
    "\n",
    "    #     .import_model('ClassificationModel', classification_model)\n",
    "#     .predict_model('ClassificationModel',\n",
    "#                      fetches=['loss', 'accuracy'],\n",
    "#                      feed_dict={'images': B('images'),\n",
    "#                                 'labels': B('labels')},\n",
    "#                      save_to=[V('loss'), V('accuracy')], \n",
    "#                      mode='a')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_ITERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqn(range(NUM_ITERS)):\n",
    "    test_ppl.next_batch(BATCH_SIZE, n_epochs=None, suffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_ppl.get_variable('loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ppl = (\n",
    "    (load_ppl << dset.test)\n",
    "    .init_variable('loss', init_on_each_run=list)\n",
    "    .init_variable('mse', init_on_each_run=list)\n",
    "    .init_variable('accuracy', init_on_each_run=list)\n",
    "    .init_variable('ce_loss', init_on_each_run=list)\n",
    "#     .import_model('NearestDetection', train_ppl)\n",
    "    .init_model('dynamic', TFModel, 'NearestDetection', config={'load': {'path': './Sailor/'}, 'build': False})\n",
    "    .predict_model('NearestDetection',\n",
    "                   fetches=fetches_list,\n",
    "                   feed_dict=saved_feed_dict,\n",
    "                   save_to=saved_fetches, \n",
    "                   mode='w')\n",
    "    .crop_predictions(n_workers=1)\n",
    "    .split_cropped()\n",
    "    .compute_confidence_accuracy()\n",
    "    \n",
    "    #     .import_model('ClassificationModel', classification_model)\n",
    "#     .predict_model('ClassificationModel',\n",
    "#                      fetches=['loss', 'accuracy'],\n",
    "#                      feed_dict={'images': B('images'),\n",
    "#                                 'labels': B('labels')},\n",
    "#                      save_to=[V('loss'), V('accuracy')], \n",
    "#                      mode='a')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ppl.get_variable('ce_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "btch = test_ppl.next_batch(batch_size=8, n_epochs=None, suffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.randint(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "btch.data.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "btch.data.cropped_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unnorm(data):\n",
    "    data = data.reshape((-1, 4))\n",
    "    data[:, 0] *= NEW_SIZE[0]\n",
    "    data[:, 2] *= NEW_SIZE[0]\n",
    "    data[:, 1] *= NEW_SIZE[1]\n",
    "    data[:, 3] *= NEW_SIZE[1]\n",
    "    return data\n",
    "\n",
    "def plot_results(btch, at_once=True):\n",
    "    index = np.random.randint(btch.data.images.shape[0])\n",
    "    img = btch.data.images[index]\n",
    "    predictions = btch.data.predicted_bb[index].reshape((-1, 5))\n",
    "    coords = unnorm(predictions[:, :4])\n",
    "    real = unnorm(btch.data.coordinates[index])\n",
    "    pred_conf = predictions[:, 4]\n",
    "    if at_once:\n",
    "        fig,ax = plt.subplots(1)\n",
    "    for i in range(8):\n",
    "        if not at_once:\n",
    "            print('pred confidence: ', pred_conf[i], 'real conf: ', btch.data.confidence[index, i, 0])\n",
    "            fig,ax = plt.subplots(1)\n",
    "            ax.imshow(img)\n",
    "            plt.show()\n",
    "        y, x, height, width = coords[i]\n",
    "        pred_rect = patches.Rectangle((x, y), width, height, linewidth=3, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(pred_rect)\n",
    "\n",
    "        y, x, height, width = real[i]\n",
    "        true_rect = patches.Rectangle((x, y), width, height, linewidth=3, edgecolor='g', facecolor='none')\n",
    "        ax.add_patch(true_rect)\n",
    "        \n",
    "\n",
    "    if at_once:\n",
    "        ax.imshow(img)\n",
    "        plt.show()\n",
    "        print('pred confidence: ', pred_conf, 'real conf: ', btch.data.confidence[index, :, 0])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "btch = test_ppl.next_batch(batch_size=8, n_epochs=None, suffle=True, drop_last=True)\n",
    "plot_results(btch, at_once=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "btch = test_ppl.next_batch(batch_size=8, n_epochs=None, suffle=True, drop_last=True)\n",
    "plot_results(btch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_ppl = (\n",
    "    Pipeline()\n",
    "    .load(src=src, fmt='blosc', components='images')\n",
    "    .load(src='labels/data.csv',\\\n",
    "          fmt='csv',\\\n",
    "          components=['coordinates', 'labels'],\\\n",
    "          index_col='file_name')\n",
    "    .crop_from_bbox()\n",
    "    .crop_background(new_size=NEW_SIZE)\n",
    "    .split_labels()\n",
    "    .split_to_digits(n_digits=8)\n",
    "    .resize(shape=(HEIGHT, WIDTH))\n",
    "    .one_hot()\n",
    "    .generate_data(n_digits=NUM_DIGITS, normalize=True, prob=0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_ppl = (\n",
    "    (load_ppl << dset.test)\n",
    "    .init_variable('loss', init_on_each_run=list)\n",
    "    .import_model(name, train_ppl)\n",
    "    .predict_model(name,\n",
    "                   fetches=fetches_list,\n",
    "                   feed_dict=saved_feed_dict,\n",
    "                   save_to=saved_fetches, \n",
    "                   mode='a')\n",
    "    )\n",
    "    .init_model('dynamic', V('model'),\n",
    "    name,\n",
    "    config=config)\n",
    "    .train_model(name,\n",
    "     fetches=fetches_list,\n",
    "     feed_dict=saved_feed_dict,\n",
    "     save_to=saved_fetches, \n",
    "     mode='a')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models was trained and reach almost the same accuracy ~ 0.9-1. Let's load one of them to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config['load'] = {'path':'./DenseNet121/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = DenseNet121(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline to predict numbers on meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_ppl = (\n",
    "    (load_ppl << dset.test)\n",
    "    .init_variable('prediction', init_on_each_run=list)\n",
    "    .init_variable('proba', init_on_each_run=list)\n",
    "    .init_variable('accuracy', init_on_each_run=list)\n",
    "    .import_model('DenseNet121', model)\n",
    "    .predict_model('DenseNet121',\n",
    "                   fetches=['output_labels',\n",
    "                            'output_proba',\n",
    "                            'output_accuracy'],\n",
    "                   make_data=make_separate_digits,\n",
    "                   save_to=[V('prediction'),\n",
    "                            V('proba'),\n",
    "                            V('accuracy')],\n",
    "                   mode='a')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot prediction numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_test = predict_ppl.next_batch(1, n_epochs=None, shuffle=True)\n",
    "\n",
    "predict = predict_ppl.get_variable('prediction')[-1]\n",
    "labels = batch_test.labels[-1]\n",
    "sepcrop = batch_test.sepcrop[-1]\n",
    "plt.title('Input image', fontsize=20)\n",
    "plt.imshow(batch_test.images[-1])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Bounding box', fontsize=20)\n",
    "plt.imshow(batch_test.cropped[-1])\n",
    "plt.grid()\n",
    "\n",
    "_, axis = plt.subplots(1, 8, figsize=(20, 10))\n",
    "axis = axis.reshape(-1)\n",
    "for i in range(8):\n",
    "    axis[i].imshow(sepcrop[i])\n",
    "    axis[i].set_title('Predict: {} \\nAnswer: {}'.format(predict[i], labels[i]), fontsize=20)\n",
    "    axis[i].grid()\n",
    "    axis[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
